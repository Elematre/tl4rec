{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca06a5ae-ffba-44e0-b0fb-d0eb6bdf3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n",
      "block_ptr: 2, offset_ptr: 0, global_ptr: 0\n",
      "block_ptr: 4, offset_ptr: 0, global_ptr: 0\n",
      "block_ptr: 0, offset_ptr: 0, global_ptr: 0\n",
      "block_ptr: 2, offset_ptr: 0, global_ptr: 1\n",
      "block_ptr: 4, offset_ptr: 0, global_ptr: 1\n",
      "block_ptr: 0, offset_ptr: 0, global_ptr: 1\n",
      "Computed output:\n",
      "tensor([[1.5200, 1.8800, 1.7600, 2.1600],\n",
      "        [0.8000, 1.0800, 0.9600, 1.2800],\n",
      "        [1.0800, 1.4000, 1.4000, 1.7600]])\n",
      "Expected output:\n",
      "tensor([[1.5200, 1.8800, 1.7600, 2.1600],\n",
      "        [0.8000, 1.0800, 0.9600, 1.2800],\n",
      "        [1.0800, 1.4000, 1.4000, 1.7600]])\n",
      "Output computation test passed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "\n",
    "# Enable device-side assertions\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "# Compile the custom kernel\n",
    "print(\"Load rspmm extension. This may take a while...\")\n",
    "path = os.getcwd()  # Use current working directory\n",
    "rspmm = load(\n",
    "    \"rspmm\",\n",
    "    [os.path.join(path, \"source/rspmm.cpp\"), os.path.join(path, \"source/rspmm.cu\")],\n",
    "    extra_cflags=[\"-DCUDA_OP\"],\n",
    "    extra_cuda_cflags=[\"--expt-relaxed-constexpr\"],\n",
    ")\n",
    "\n",
    "# Define an undirected test graph with two edge types\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 0], [1, 0, 2, 1, 0, 2]], dtype=torch.long)  # Undirected edges\n",
    "edge_type = torch.tensor([0, 1, 0, 1, 0, 1], dtype=torch.long)  # Edge types for each direction\n",
    "edge_weight = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=torch.float32)  # Weights for edges\n",
    "edge_attr = torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6], [0.7, 0.8], [0.9, 1.0], [1.1, 1.2]], dtype=torch.float32)  # Edge attributes\n",
    "relation = torch.tensor([[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0]], dtype=torch.float32)  # Placeholder\n",
    "input_feat = torch.tensor([[0.5, 0.6, 0.7, 0.8], [0.9, 1.0, 1.1, 1.2], [1.3, 1.4, 1.5, 1.6]], dtype=torch.float32)  # Node features (dim=4)\n",
    "# Minimal test graph: 2 nodes, 1 edge\n",
    "#edge_index = torch.tensor([[0,1], [1,0]], dtype=torch.int64)\n",
    "#edge_type = torch.tensor([0,1], dtype=torch.int64)\n",
    "#edge_weight = torch.tensor([1.0,1.0], dtype=torch.float32)\n",
    "#edge_attr = torch.tensor([[0.1], [0.2]], dtype=torch.float32)\n",
    "#relation = torch.tensor([[1.0, 1.0],[1.0, 1.0]], dtype=torch.float32)  # Placeholder\n",
    "#input_feat = torch.tensor([[0.1, 0.2], [0.3, 0.4]], dtype=torch.float32)\n",
    "\n",
    "# Move tensors to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "edge_index = edge_index.to(device)\n",
    "edge_type = edge_type.to(device)\n",
    "edge_weight = edge_weight.to(device)\n",
    "edge_attr = edge_attr.to(device)\n",
    "relation = relation.to(device)\n",
    "input_feat = input_feat.to(device)\n",
    "\n",
    "# Ensure edges are sorted according to the logic in generalized_rspmm\n",
    "node_in, node_out = edge_index\n",
    "key = node_in * (node_out.max() + 1) + node_out\n",
    "order = key.argsort()\n",
    "sorted_edge_index = edge_index[:, order]\n",
    "sorted_edge_type = edge_type[order]\n",
    "sorted_edge_weight = edge_weight[order]\n",
    "sorted_edge_attr = edge_attr[order, :]\n",
    "\n",
    "# Forward pass using custom kernel\n",
    "output = rspmm.rspmm_add_mul_forward_cuda(\n",
    "    sorted_edge_index, sorted_edge_type, sorted_edge_weight, sorted_edge_attr, relation, input_feat\n",
    ")\n",
    "\n",
    "# Move output back to CPU for comparison\n",
    "output = output.cpu()\n",
    "\n",
    "# Manual output computation for validation\n",
    "expected_output = torch.zeros_like(input_feat).cpu()\n",
    "for idx, (u, v) in enumerate(sorted_edge_index.t().cpu()):\n",
    "    for d in range(input_feat.size(1)):\n",
    "        attr = sorted_edge_attr[idx, d % sorted_edge_attr.size(1)].cpu()\n",
    "        in_feat = input_feat[v, d].cpu()\n",
    "        weight = sorted_edge_weight[idx].cpu()\n",
    "        expected_output[u, d] += weight * attr * in_feat\n",
    "\n",
    "# Compare the computed output with the expected one\n",
    "print(\"Computed output:\")\n",
    "print(output)\n",
    "\n",
    "print(\"Expected output:\")\n",
    "print(expected_output)\n",
    "\n",
    "# Validation\n",
    "assert torch.allclose(output, expected_output, atol=1e-6), \"Output mismatch detected!\"\n",
    "print(\"Output computation test passed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f3e31-c97f-4f71-a063-a9535a391dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_bugfix",
   "language": "python",
   "name": "ba_bugfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
