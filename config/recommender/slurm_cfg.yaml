output_dir: /itet-stor/trachsele/net_scratch/tl4rec/model_outputs/logs

dataset:
  class: {{ dataset }}
  root: /itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data

#the input dim of the entity_model needs to be output_dim relation_model + output_dim embedding_model


model:
  class: Gru-Ultra
  node_features: no
  user_projection:
   use_dropout: yes
   dropout_rate: 0.1
   use_layer_norm: yes
   hidden_dims: [32]
  item_projection: 
   use_dropout: yes
   dropout_rate: 0.1
   use_layer_norm: yes
   hidden_dims: [32]
  backbone_model:
    simple_model:
      class: SimpleNBFNet
      input_dim: 32
      hidden_dims: [32, 32, 32, 32, 32, 32, 32]
      message_func: distmult
      aggregate_func: sum
      short_cut: yes
      layer_norm: yes
      # CONSTRAINT: entity_model_inputdim = node_embedding_output_dim +  relation_embedding_output_dim
    embedding_user:
      use_dropout: no
      dropout_rate: 0.1
      use_layer_norm: no
      hidden_dims: [32, 32]
    embedding_item:
      use_dropout: no
      dropout_rate: 0.1
      use_layer_norm: no
      hidden_dims: [32, 32]


task:
  name: TransductiveInference
  num_negative: 54
  strict_negative: yes
  adversarial_temperature: 1
  metric: [mr, mrr, hits@1, hits@3, hits@10, ndcg@20]
  # note if one changes the k from ndcg this should also be adjusted in the code

optimizer:
  class: AdamW
  lr:  0.00017783663799881164

train:
  gpus: {{ gpus }}
  batch_size: 16
  num_epoch: {{ epochs }}
  log_interval: 100
  batch_per_epoch: {{ bpe }}
  loss: bce # Options: Bpr, bce
  target_metric: ndcg@20
  wandb: yes
  gradient_clip: no
  init_linear_weights: yes
  num_evals: 10
  # true num_evals is calculated by: ceil(num_epoch / num_evals)
  test_batch_size: 8
  fine_tuning:
    num_epoch_proj: 1
   
      

checkpoint: {{ ckpt }}
