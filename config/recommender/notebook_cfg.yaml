output_dir: /itet-stor/trachsele/net_scratch/tl4rec/model_outputs/logs

dataset:
  class: {{ dataset }}
  root: /itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data

#the input dim of the entity_model needs to be output_dim relation_model + output_dim embedding_model
# projection_dim = embedding_dim
# simple_model_dim % edge_dim == 0!
 
model:
  class: Gru-Ultra
  node_features: no
  edge_features: yes
  user_projection:
   use_dropout: yes
   dropout_rate: 0.1
   use_layer_norm: no
   hidden_dims: [32]
  item_projection: 
   use_dropout: yes
   dropout_rate: 0.1
   use_layer_norm: yes
   hidden_dims: [32]
  edge_projection: 
   use_dropout: yes
   dropout_rate: 0.1
   use_layer_norm: yes
   hidden_dims: [4]
  backbone_model:
    simple_model:
      class: SimpleNBFNet
      input_dim: 40
      hidden_dims: [40, 40,40, 40]
      message_func: distmult
      aggregate_func: sum
      short_cut: yes
      layer_norm: yes
      project_conv_emb: yes
      # CONSTRAINT: entity_model_inputdim = node_embedding_output_dim +  relation_embedding_output_dim
    embedding_user:
      use_dropout: no
      dropout_rate: 0.1
      use_layer_norm: no
      hidden_dims: [16, 16]
    embedding_item:
      use_dropout: no
      dropout_rate: 0.1
      use_layer_norm: no
      hidden_dims: [16, 16]
    embedding_edge:
      use_dropout: yes
      dropout_rate: 0.2 
      use_layer_norm: yes
      hidden_dims: [4, 4, 4]
    #0.05

task:
  name: TransductiveInference
  num_negative: 8
  strict_negative: yes
  adversarial_temperature: 0
  metric: [mr, mrr, hits@1, hits@3, hits@10, ndcg@20]
  # note if one changes the k from ndcg this should also be adjusted in the code

optimizer:
  class: AdamW
  lr:  0.005

train:
  gpus: [{{ gpus }}]
  batch_size: 8
  num_epoch: {{ epochs }}
  log_interval: 100
  batch_per_epoch: {{ bpe }}
  loss: bce # Options: Bpr, bce
  target_metric: ndcg@20
  wandb: no
  gradient_clip: no
  init_linear_weights: yes
  num_evals: 10
  # true num_evals is calculated by: ceil(num_epoch / num_evals)
  test_batch_size: 8
  fine_tuning:
    num_epoch_proj: 0
   
      

checkpoint: {{ ckpt }}
