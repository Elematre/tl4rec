{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e420fee2-0240-4834-a5d7-55c66184323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import MovieLens1M\n",
    "\n",
    "# Load MovieLens 1M dataset (adjust root if needed)\n",
    "dataset = MovieLens1M(root='/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/temp_pyg')\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4ec27-380c-4209-84f9-8e31320a28a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60bc3c5-a16b-4780-8342-c6f78b21f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 6039, 6039, 6039],\n",
      "        [1176,  655,  902,  ...,  558, 1080, 1081]])\n"
     ]
    }
   ],
   "source": [
    "graph = dataset[0]\n",
    "print(graph['user', 'rates', 'movie'].edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98371c13-d2c7-430d-8715-d0ca90ab48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  movie={ x=[3883, 18] },\n",
      "  user={ x=[6040, 30] },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 1000209],\n",
      "    rating=[1000209],\n",
      "    time=[1000209],\n",
      "  },\n",
      "  (movie, rated_by, user)={\n",
      "    edge_index=[2, 1000209],\n",
      "    rating=[1000209],\n",
      "    time=[1000209],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56fd6e07-ceb2-42fb-83b9-2e8d939d5da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1176), (0, 0, 655), (0, 0, 902), (0, 0, 3339), (0, 0, 2286), (0, 0, 1179), (0, 0, 1267), (0, 0, 2735), (0, 0, 590), (0, 0, 907)]\n"
     ]
    }
   ],
   "source": [
    "#reading the edges\n",
    "edges = graph['user', 'rates', 'movie'].edge_index\n",
    "\n",
    "triplets = []\n",
    "for i in range(edges.size(1)):\n",
    "    u, v = edges[:, i]  # Get the user and movie node index\n",
    "    triplets.append((u.item(),0, v.item()))\n",
    "\n",
    "print(triplets[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add007f2-af90-4f14-ab17-71747cd0d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(triplets)\n",
    "num_train = int(0.8 * len(triplets))\n",
    "num_val = int(0.1 * len(triplets))\n",
    "\n",
    "train_triplets = triplets[:num_train]\n",
    "val_triplets = triplets[num_train:num_train + num_val]\n",
    "test_triplets = triplets[num_train + num_val:]\n",
    "\n",
    "\n",
    "# Save them into separate files\n",
    "def save_triplets(filename, triplets):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for u, v, e in triplets:\n",
    "            f.write(f\"{u}\\t{v}\\t{e}\\n\")\n",
    "\n",
    "save_triplets(\"train.txt\", train_triplets)\n",
    "save_triplets(\"valid.txt\", val_triplets)\n",
    "save_triplets(\"test.txt\", test_triplets)\n",
    "print (\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51b938-df62-4402-bbd5-f3832f447c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MovieLens1M_pyG CoDExSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d2588a-3d3a-4878-8a13-a10a92d70c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:39:11   Random seed: 1024\n",
      "14:39:11   Config file: config/transductive/inference.yaml\n",
      "14:39:11   {'checkpoint': '/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ckpts/ultra_4g.pth',\n",
      " 'dataset': {'class': 'CoDExSmall', 'root': '~/git/ULTRA/kg-datasets/'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                            'input_dim': 64,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                              'input_dim': 64,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True}},\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
      " 'output_dir': '~/git/ULTRA/output',\n",
      " 'task': {'adversarial_temperature': 1,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 256,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': None,\n",
      "           'batch_size': 8,\n",
      "           'gpus': [0],\n",
      "           'log_interval': 100,\n",
      "           'num_epoch': 0}}\n",
      "14:39:11   CoDExSmall dataset\n",
      "14:39:11   #train: 32888, #valid: 1827, #test: 1828\n",
      "14:39:12   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:39:12   Evaluate on valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:39:28   mr: 38.5285\n",
      "14:39:29   mrr: 0.477777\n",
      "14:39:29   hits@1: 0.37329\n",
      "14:39:29   hits@3: 0.529557\n",
      "14:39:29   hits@10: 0.676793\n",
      "14:39:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:39:29   Evaluate on test\n",
      "14:39:38   mr: 42.3884\n",
      "14:39:38   mrr: 0.463778\n",
      "14:39:38   hits@1: 0.360503\n",
      "14:39:38   hits@3: 0.514497\n",
      "14:39:38   hits@10: 0.665208\n"
     ]
    }
   ],
   "source": [
    "%run script/run.py -c config/transductive/inference.yaml --dataset CoDExSmall --epochs 0 --bpe null --gpus [0] --ckpt /usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ckpts/ultra_4g.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6700fa38-a07d-4f5a-b665-c709694fb6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:49:49   Random seed: 1024\n",
      "14:49:49   Config file: config/transductive/inference.yaml\n",
      "14:49:49   {'checkpoint': '/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ckpts/ultra_4g.pth',\n",
      " 'dataset': {'class': 'MovieLens1M_pyG', 'root': '~/git/ULTRA/kg-datasets/'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                            'input_dim': 64,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
      "                              'input_dim': 64,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True}},\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
      " 'output_dir': '~/git/ULTRA/output',\n",
      " 'task': {'adversarial_temperature': 1,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 256,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': None,\n",
      "           'batch_size': 8,\n",
      "           'gpus': [0],\n",
      "           'log_interval': 100,\n",
      "           'num_epoch': 0}}\n",
      "Downloading https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/MovieLenseData/train_full.txt\n",
      "Downloading https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/MovieLenseData/valid_small.txt\n",
      "Downloading https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/MovieLenseData/test_small.txt\n",
      "Processing...\n",
      "/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/tasks.py:181: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  Ahh = torch.sparse.mm(EhT, Eh).coalesce()\n",
      "Done!\n",
      "14:50:25   MovieLens1M_pyG dataset\n",
      "14:50:25   #train: 800167, #valid: 100, #test: 100\n",
      "14:50:25   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:50:25   Evaluate on valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:50:32   mr: 792.05\n",
      "14:50:32   mrr: 0.0139796\n",
      "14:50:32   hits@1: 0\n",
      "14:50:32   hits@3: 0.005\n",
      "14:50:32   hits@10: 0.035\n",
      "14:50:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:50:32   Evaluate on test\n",
      "14:50:39   mr: 772.72\n",
      "14:50:39   mrr: 0.00928851\n",
      "14:50:39   hits@1: 0\n",
      "14:50:39   hits@3: 0.005\n",
      "14:50:39   hits@10: 0.02\n"
     ]
    }
   ],
   "source": [
    "%run script/run.py -c config/transductive/inference.yaml --dataset MovieLens1M_pyG --epochs 0 --bpe null --gpus [0] --ckpt /usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ckpts/ultra_4g.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a51668e-e2a1-4613-be35-3305a3e138d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n",
      "2.1.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(np.__version__)  # Check NumPy version\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.cuda.is_available())  # Check if CUDA is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77512c9d-00a8-40e8-8f75-ec3e7993b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/trachsele/git/ULTRA/output/Ultra/CoDExSmall/2024-10-12-14-39-11\n",
      "/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f89f1e-7b75-491c-9c8d-303b939e0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['valid.txt', 'requirements.txt', 'MovieLense_load.ipynb', 'temp_pyg', 'config', '.git', '.gitignore', 'ultra', 'LICENSE', 'script', 'test.txt', 'train.txt', 'ckpts', 'asset', 'README.md', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0230f231-7cd1-493e-a69d-055d78affeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All nodes in valid are in train.\n",
      "All nodes in test are in train.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URLs of the triplet files\n",
    "urls = {\n",
    "    \"train\": \"https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/train.txt\",\n",
    "    \"valid\": \"https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/valid.txt\",\n",
    "    \"test\": \"https://raw.githubusercontent.com/Elematre/tl4rec/refs/heads/main/test.txt\",\n",
    "}\n",
    "\n",
    "# Function to load triplet data from a URL\n",
    "def load_triplets(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we got the data correctly\n",
    "    triplets = [line.strip().split() for line in response.text.splitlines()]\n",
    "    return triplets\n",
    "\n",
    "# Function to extract the set of unique nodes from triplets\n",
    "def get_unique_nodes(triplets):\n",
    "    nodes = set()\n",
    "    for triplet in triplets:\n",
    "        u, e, v = triplet\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "    return nodes\n",
    "\n",
    "# Load triplet data from URLs\n",
    "train_triplets = load_triplets(urls[\"train\"])\n",
    "valid_triplets = load_triplets(urls[\"valid\"])\n",
    "test_triplets = load_triplets(urls[\"test\"])\n",
    "\n",
    "# Extract unique nodes\n",
    "train_nodes = get_unique_nodes(train_triplets)\n",
    "valid_nodes = get_unique_nodes(valid_triplets)\n",
    "test_nodes = get_unique_nodes(test_triplets)\n",
    "\n",
    "# Find missing nodes in valid and test datasets\n",
    "missing_in_valid = valid_nodes - train_nodes\n",
    "missing_in_test = test_nodes - train_nodes\n",
    "\n",
    "# Print results\n",
    "if missing_in_valid:\n",
    "    print(f\"Nodes in valid but not in train: {missing_in_valid}\")\n",
    "else:\n",
    "    print(\"All nodes in valid are in train.\")\n",
    "\n",
    "if missing_in_test:\n",
    "    print(f\"Nodes in test but not in train: {missing_in_test}\")\n",
    "else:\n",
    "    print(\"All nodes in test are in train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99d543-9391-44e0-90cc-917ca2c0ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ba_bugfix)",
   "language": "python",
   "name": "ba_bugfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
