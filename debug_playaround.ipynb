{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420fee2-0240-4834-a5d7-55c66184323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import MovieLens1M, MovieLens100K\n",
    "\n",
    "\n",
    "# Load MovieLens 1M dataset (adjust root if needed)\n",
    "#dataset = MovieLens1M(root='/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/temp_pyg')\n",
    "dataset= MovieLens100K(root=\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/temp_pyg\")\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a4db48-f865-42f6-abe7-7c5145a6198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Embedding Tensor:\n",
      " tensor([[0.1000, 0.2000],\n",
      "        [0.3000, 0.4000],\n",
      "        [0.5000, 0.6000]])\n",
      "Item Embedding Tensor:\n",
      " tensor([[0.7000, 0.8000],\n",
      "        [0.9000, 1.0000],\n",
      "        [1.1000, 1.2000]])\n",
      "Head Embeddings:\n",
      " tensor([[[0.1000, 0.2000],\n",
      "         [0.1000, 0.2000],\n",
      "         [0.1000, 0.2000]],\n",
      "\n",
      "        [[0.3000, 0.4000],\n",
      "         [0.5000, 0.6000],\n",
      "         [0.1000, 0.2000]]])\n",
      "Tail Embeddings:\n",
      " tensor([[[0.7000, 0.8000],\n",
      "         [0.9000, 1.0000],\n",
      "         [1.1000, 1.2000]],\n",
      "\n",
      "        [[0.9000, 1.0000],\n",
      "         [0.9000, 1.0000],\n",
      "         [0.9000, 1.0000]]])\n",
      "size head Embeddings:\n",
      " torch.Size([2, 3, 2])\n",
      "size Tail Embeddings:\n",
      " torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "num_negatives = 2\n",
    "num_users = 3\n",
    "num_items = 3\n",
    "dim = 2\n",
    "\n",
    "# Embeddings for users and items (3 users, 3 items, embedding dimension 2)\n",
    "user_embedding = torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "item_embedding = torch.tensor([[0.7, 0.8], [0.9, 1.0], [1.1, 1.2]])\n",
    "\n",
    "# h_index and t_index based on the edges and negative samples\n",
    "# Each row represents a batch entry, and each column is a negative sample\n",
    "# Here, `0` and `1` are valid head indices (users), and we corrupt them by keeping valid and invalid tails\n",
    "h_index = torch.tensor([\n",
    "    [0, 0, 0],  # For first edge (0, 0, 3) with two negatives\n",
    "    [1, 2, 0]   # For second edge (1, 0, 4) with two negatives\n",
    "])\n",
    "t_index = torch.tensor([\n",
    "    [3, 4, 5],  # Original (0, 0, 3), and corrupted tails [4, 2]\n",
    "    [4, 4, 4]   # Original (1, 0, 4), and corrupted tails [5, 0]\n",
    "])\n",
    "\n",
    "# Gather head node embeddings\n",
    "# (num_nodes, dim)\n",
    "index_temp = h_index.unsqueeze(-1).expand(-1, -1, user_embedding.shape[-1])\n",
    "h_embeddings = user_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, h_index.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "# Adjust `t_index` to map to item IDs by subtracting `num_users`\n",
    "index_temp = (t_index - num_users).clamp(min=0)\n",
    "t_embeddings = item_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, index_temp.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "print(\"User Embedding Tensor:\\n\", user_embedding)\n",
    "print(\"Item Embedding Tensor:\\n\", item_embedding)\n",
    "print(\"Head Embeddings:\\n\", h_embeddings)\n",
    "print(\"Tail Embeddings:\\n\", t_embeddings)\n",
    "print(\"size head Embeddings:\\n\", h_embeddings.shape)\n",
    "print(\"size Tail Embeddings:\\n\", t_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bc3c5-a16b-4780-8342-c6f78b21f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "plot_ratings_vs_time(data)\n",
    "#print (data)\n",
    "#print (data['user', 'rates', 'movie'].rating[:20])\n",
    "#print (graph[\"movie\"].x[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9134d9-f7d4-4abd-82de-c51570b0aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0.])]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t_ranking = torch.zeros(5)\n",
    "h_ranking = torch.zeros(6)\n",
    "rankings1 = [t_ranking, h_ranking]\n",
    "print(rankings1)\n",
    "rankings2 = torch.cat([t_ranking, h_ranking], dim=0)\n",
    "print(rankings2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130c7989-98c0-4e7e-bbe7-04481f50f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_features = graph[\"user\"].x\n",
    "print (movies_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d51b938-df62-4402-bbd5-f3832f447c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2588a-3d3a-4878-8a13-a10a92d70c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") \n",
    "%run script/run.py -c config/transductive/inference.yaml --dataset WN18RR --epochs 0 --bpe null --gpus [0] --ckpt /usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ckpts/ultra_4g.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd6aac0-77b8-4bbe-910c-f41567b4d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "11:57:43   Random seed: 1024\n",
      "11:57:43   Config file: config/recommender/notebook_cfg.yaml\n",
      "11:57:43   {'checkpoint': None,\n",
      " 'dataset': {'class': 'Amazon_Beauty',\n",
      "             'root': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'embedding_item': {'hidden_dims': [32, 32], 'input_dim': 6507},\n",
      "           'embedding_user': {'hidden_dims': [32, 32], 'input_dim': 1},\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [32, 32, 32, 32, 32],\n",
      "                            'input_dim': 32,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [8, 8],\n",
      "                              'input_dim': 8,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True},\n",
      "           'simple_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'SimpleNBFNet',\n",
      "                            'hidden_dims': [40, 40, 40, 40],\n",
      "                            'input_dim': 40,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True}},\n",
      " 'model_type': 'Ultra',\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.005},\n",
      " 'output_dir': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/logs',\n",
      " 'task': {'adversarial_temperature': 0,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10', 'ndcg@20'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 1,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': 10,\n",
      "           'batch_size': 8,\n",
      "           'gpus': [0],\n",
      "           'gradient_clip': False,\n",
      "           'init_linear_weights': False,\n",
      "           'log_interval': 100,\n",
      "           'loss': 'bpr',\n",
      "           'num_epoch': 1,\n",
      "           'num_evals': 10,\n",
      "           'target_metric': 'ndcg@20',\n",
      "           'test_batch_size': 8,\n",
      "           'wandb': False}}\n",
      "11:57:45   Amazon_Beauty dataset\n",
      "11:57:45   #train: 293912, #valid: 50498, #test: 50498\n",
      "11:57:46   ------------------------------\n",
      "11:57:46   Number of parameters: 264433\n",
      "11:57:46   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "11:57:46   Epoch 0 begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using Ultra\n",
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "11:57:47   Mean positive scores: -0.1768583208322525\n",
      "11:57:47   Mean negative scores: -0.1414882242679596\n",
      "11:57:47   BPR loss: 0.7132311463356018\n",
      "11:57:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "11:57:49   Epoch 0 end\n",
      "11:57:49   ------------------------------\n",
      "11:57:49   average loss: 0.851646\n",
      "11:57:49   Save checkpoint to model_epoch_1.pth\n",
      "11:57:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "11:57:49   Evaluate on valid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/script/run.py:452\u001b[0m\n\u001b[1;32m    448\u001b[0m val_filtered_data \u001b[38;5;241m=\u001b[39m val_filtered_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    449\u001b[0m test_filtered_data \u001b[38;5;241m=\u001b[39m test_filtered_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 452\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_filtered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mget_rank() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    454\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(separator)\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/script/run.py:155\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(cfg, model, train_data, valid_data, device, logger, filtered_data, batch_per_epoch)\u001b[0m\n\u001b[1;32m    151\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(separator)\n\u001b[1;32m    152\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate on valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Log each metric with the hierarchical key format \"training/performance/{metric}\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb_on:\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/script/run.py:196\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(cfg, model, test_data, device, logger, filtered_data, return_metrics, valid_data)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m#h_batch= t_batch= (bs, num_nodes, 3)\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     t_batch, h_batch \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mall_negative(test_data, batch)\n\u001b[0;32m--> 196\u001b[0m     t_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     h_pred \u001b[38;5;241m=\u001b[39m model(test_data, h_batch)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m#t_pred= (bs, num_nodes)\u001b[39;00m\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/models.py:65\u001b[0m, in \u001b[0;36mUltra.forward\u001b[0;34m(self, data, batch)\u001b[0m\n\u001b[1;32m     63\u001b[0m user_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_mlp(data\u001b[38;5;241m.\u001b[39mx_user)  \u001b[38;5;66;03m# shape: (num_users, 16)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m item_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_mlp(data\u001b[38;5;241m.\u001b[39mx_item)\n\u001b[0;32m---> 65\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# what does score look like? score (batch_size, 1 + num negatives)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/models.py:240\u001b[0m, in \u001b[0;36mSimpleNBFNet.forward\u001b[0;34m(self, data, batch, user_embedding, item_embedding)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (r_index[:, [\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m==\u001b[39m r_index)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# message passing and updated node representations\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbellmanford\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_embeddings\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (num_nodes, batch_size, feature_dim）\u001b[39;00m\n\u001b[1;32m    241\u001b[0m feature \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    242\u001b[0m index \u001b[38;5;241m=\u001b[39m t_index\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m#unsequeeze adds dimensions on top leve x^2 to x^3 expand changes how many rows\u001b[39;00m\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/models.py:177\u001b[0m, in \u001b[0;36mSimpleNBFNet.bellmanford\u001b[0;34m(self, data, h_index, user_embedding, item_embedding, h_embeddings, separate_grad)\u001b[0m\n\u001b[1;32m    173\u001b[0m layer_input \u001b[38;5;241m=\u001b[39m boundary\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Bellman-Ford iteration, we send the original boundary condition in addition to the updated node states\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_cut \u001b[38;5;129;01mand\u001b[39;00m hidden\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m layer_input\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# residual connection here\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         hidden \u001b[38;5;241m=\u001b[39m hidden \u001b[38;5;241m+\u001b[39m layer_input\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/layers.py:89\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.forward\u001b[0;34m(self, input, query, boundary, edge_index, edge_type, size, edge_weight)\u001b[0m\n\u001b[1;32m     85\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(edge_type), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# note that we send the initial boundary condition (node states at layer0) to the message passing\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# correspond to Eq.6 on p5 in https://arxiv.org/pdf/2106.06935.pdf\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                        \u001b[49m\u001b[43medge_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/layers.py:121\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         edge_index, msg_aggr_kwargs \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 121\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_aggr_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    123\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, msg_aggr_kwargs), out)\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/layers.py:204\u001b[0m, in \u001b[0;36mGeneralizedRelationalConv.message_and_aggregate\u001b[0;34m(self, edge_index, input, relation, boundary, edge_type, edge_weight, index, dim_size)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown message function `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m     update \u001b[38;5;241m=\u001b[39m \u001b[43mgeneralized_rspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmul\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     update \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m+\u001b[39m boundary\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/rspmm/rspmm.py:178\u001b[0m, in \u001b[0;36mgeneralized_rspmm\u001b[0;34m(edge_index, edge_type, edge_weight, relation, input, sum, mul)\u001b[0m\n\u001b[1;32m    175\u001b[0m key \u001b[38;5;241m=\u001b[39m node_in \u001b[38;5;241m*\u001b[39m (node_out\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m node_out\n\u001b[1;32m    176\u001b[0m order \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39margsort()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type\u001b[49m\u001b[43m[\u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m[\u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/ultra/rspmm/rspmm.py:17\u001b[0m, in \u001b[0;36mRSPMMAddMulFunction.forward\u001b[0;34m(ctx, edge_index, edge_type, edge_weight, relation, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m node_in, node_out \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[1;32m     16\u001b[0m key \u001b[38;5;241m=\u001b[39m node_in \u001b[38;5;241m*\u001b[39m (node_out\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m node_out\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (key\u001b[38;5;241m.\u001b[39mdiff() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect sorted `edge_index`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     20\u001b[0m     forward \u001b[38;5;241m=\u001b[39m rspmm\u001b[38;5;241m.\u001b[39mrspmm_add_mul_forward_cuda\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Amazon_Beauty --epochs 1 --bpe 10 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667960bc-c845-42a2-b821-68afbfd13555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset MovieLens100k --epochs 1 --bpe 10 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700fa38-a07d-4f5a-b665-c709694fb6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "12:33:33   Random seed: 1024\n",
      "12:33:33   Config file: config/recommender/notebook_cfg.yaml\n",
      "12:33:33   {'checkpoint': None,\n",
      " 'dataset': {'class': 'Yelp18',\n",
      "             'root': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data'},\n",
      " 'model': {'class': 'Ultra',\n",
      "           'embedding_item': {'hidden_dims': [32, 32], 'input_dim': 6421},\n",
      "           'embedding_user': {'hidden_dims': [32, 32], 'input_dim': 20},\n",
      "           'entity_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'EntityNBFNet',\n",
      "                            'hidden_dims': [32, 32, 32, 32, 32],\n",
      "                            'input_dim': 32,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True},\n",
      "           'relation_model': {'aggregate_func': 'sum',\n",
      "                              'class': 'RelNBFNet',\n",
      "                              'hidden_dims': [8, 8],\n",
      "                              'input_dim': 8,\n",
      "                              'layer_norm': True,\n",
      "                              'message_func': 'distmult',\n",
      "                              'short_cut': True},\n",
      "           'simple_model': {'aggregate_func': 'sum',\n",
      "                            'class': 'SimpleNBFNet',\n",
      "                            'hidden_dims': [40, 40, 40, 40],\n",
      "                            'input_dim': 40,\n",
      "                            'layer_norm': True,\n",
      "                            'message_func': 'distmult',\n",
      "                            'short_cut': True}},\n",
      " 'model_type': 'Ultra',\n",
      " 'optimizer': {'class': 'AdamW', 'lr': 0.005},\n",
      " 'output_dir': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/logs',\n",
      " 'task': {'adversarial_temperature': 0,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10', 'ndcg@20'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 8,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': 10,\n",
      "           'batch_size': 32,\n",
      "           'gpus': [0],\n",
      "           'gradient_clip': False,\n",
      "           'init_linear_weights': False,\n",
      "           'log_interval': 100,\n",
      "           'loss': 'bpr',\n",
      "           'num_epoch': 1,\n",
      "           'num_evals': 10,\n",
      "           'target_metric': 'ndcg@20',\n",
      "           'test_batch_size': 8,\n",
      "           'wandb': False}}\n",
      "12:33:34   Yelp18 dataset\n",
      "12:33:34   #train: 1097007, #valid: 140252, #test: 324147\n",
      "12:33:35   ------------------------------\n",
      "12:33:35   Number of parameters: 262289\n",
      "12:33:35   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "12:33:35   Epoch 0 begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using Ultra\n",
      "Load rspmm extension. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:38   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "12:33:38   Mean positive scores: -0.04674626141786575\n",
      "12:33:38   Mean negative scores: -0.039863523095846176\n",
      "12:33:38   BPR loss: 0.6967812180519104\n",
      "12:33:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "12:33:55   Epoch 0 end\n",
      "12:33:55   ------------------------------\n",
      "12:33:55   average loss: 0.632524\n",
      "12:33:55   Save checkpoint to model_epoch_1.pth\n",
      "12:33:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "12:33:55   Evaluate on valid\n",
      "13:17:26   mr: 10684.8\n",
      "13:17:26   mrr: 0.00382965\n",
      "13:17:26   hits@1: 0.00127627\n",
      "13:17:26   hits@3: 0.00289479\n",
      "13:17:26   hits@10: 0.00699455\n",
      "13:17:26   ndcg@20: 0.000477841\n",
      "13:17:26   Load checkpoint from model_epoch_1.pth\n",
      "13:17:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "13:17:26   Evaluate on valid\n",
      "14:00:56   mr: 10684.8\n",
      "14:00:56   mrr: 0.00382965\n",
      "14:00:56   hits@1: 0.00127627\n",
      "14:00:56   hits@3: 0.00289479\n",
      "14:00:56   hits@10: 0.00699455\n",
      "14:00:56   ndcg@20: 0.000477841\n",
      "14:00:56   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:00:56   Evaluate on test\n"
     ]
    }
   ],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Yelp18 --epochs 1 --bpe 10 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51668e-e2a1-4613-be35-3305a3e138d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(np.__version__)  # Check NumPy version\n",
    "print(torch.__version__)  # Check PyTorch version\n",
    "print(torch.cuda.is_available())  # Check if CUDA is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77512c9d-00a8-40e8-8f75-ec3e7993b842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f89f1e-7b75-491c-9c8d-303b939e0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "Number of entries: 287107\n",
      "Number of entries: 287107\n",
      "Key 0: (352, 60), Value: [0.0, 0.5, 0.7419354838709677, 0.2857142857142857, 0.4767123287671233, 6.25]\n",
      "Key 1: (1814, 647), Value: [0.0, 0.8333333333333334, 0.45161290322580644, 0.42857142857142855, 0.7863013698630137, 10.25]\n",
      "Key 2: (1796, 619), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 3: (1504, 173), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 4: (1504, 364), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 5: (1504, 592), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 6: (1504, 785), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 7: (1504, 797), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 8: (1504, 827), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n",
      "Key 9: (1796, 836), Value: [0.0, 0.9166666666666666, 0.3225806451612903, 0.2857142857142857, 0.8602739726027397, 11.25]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def inspect_cxtdict(cxtdict):\n",
    "    print(\"Type:\", type(cxtdict))\n",
    "    print(\"Number of entries:\", len(cxtdict))\n",
    "    if isinstance(cxtdict, dict):\n",
    "        print(\"Number of entries:\", len(cxtdict))\n",
    "        # Print a sample of the keys and values\n",
    "        for i, key in enumerate(cxtdict.keys()):\n",
    "            print(f\"Key {i}: {key}, Value: {cxtdict[key]}\")\n",
    "            if i >= 9:  # Limit to first 10 entries\n",
    "                break\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    try:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            x= pickle.load(f)\n",
    "    except:\n",
    "        x = []\n",
    "    return x\n",
    "    \n",
    "CXTDict = load_data('/itet-stor/trachsele/net_scratch/tl4rec/CARCA_Code_and_Data/Data/CXTDictSasRec_Games.dat')\n",
    "inspect_cxtdict(CXTDict)\n",
    "#print(CXTDict)\n",
    "#print(CXTDict[(1,49583)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c99d543-9391-44e0-90cc-917ca2c0ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpitri\u001b[0m (\u001b[33mpitri-eth-z-rich\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/wandb/run-20241018_142125-w4bdlpsv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project/runs/w4bdlpsv' target=\"_blank\">rose-feather-1</a></strong> to <a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project' target=\"_blank\">https://wandb.ai/pitri-eth-z-rich/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project/runs/w4bdlpsv' target=\"_blank\">https://wandb.ai/pitri-eth-z-rich/my-awesome-project/runs/w4bdlpsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▂▁▇▆▆▇█▇</td></tr><tr><td>loss</td><td>█▃▃▃▄▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.83106</td></tr><tr><td>loss</td><td>0.0692</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-feather-1</strong> at: <a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project/runs/w4bdlpsv' target=\"_blank\">https://wandb.ai/pitri-eth-z-rich/my-awesome-project/runs/w4bdlpsv</a><br/> View project at: <a href='https://wandb.ai/pitri-eth-z-rich/my-awesome-project' target=\"_blank\">https://wandb.ai/pitri-eth-z-rich/my-awesome-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241018_142125-w4bdlpsv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c8dba-5c11-46ab-872d-bf66245d1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ba_bugfix)",
   "language": "python",
   "name": "ba_bugfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
