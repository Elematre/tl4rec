{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e420fee2-0240-4834-a5d7-55c66184323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test interactions per user: 9.729940414428711\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultra import datasets\n",
    "from torch_geometric.datasets import MovieLens1M, MovieLens100K\n",
    "\n",
    "\n",
    "# Load MovieLens 1M dataset (adjust root if needed) push test\n",
    "#dataset = MovieLens1M(root='/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/temp_pyg')\n",
    "dataset= datasets.Epinions(root= \"/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data\")\n",
    "test= dataset[2]\n",
    "\n",
    "# Assuming test.target_edge_index is defined and is a tensor of shape (2, num_edges)\n",
    "user_ids = test.target_edge_index[0]  # row 0 contains user indices\n",
    "unique_users, counts = torch.unique(user_ids, return_counts=True)\n",
    "avg_interactions = counts.float().mean().item()\n",
    "print(\"Average test interactions per user:\", avg_interactions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c8c673-780a-48bb-a83c-36e887e631dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].edge_index.shapetorch.Size([2, 2194014])\n"
     ]
    }
   ],
   "source": [
    "from ultra import datasets\n",
    "\n",
    "dataset = datasets.Yelp18(root = \"/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data\")\n",
    "print (f\"dataset[0].edge_index.shape{: dataset[0].edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4db48-f865-42f6-abe7-7c5145a6198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "num_negatives = 2\n",
    "num_users = 3\n",
    "num_items = 3\n",
    "dim = 2\n",
    "\n",
    "# Embeddings for users and items (3 users, 3 items, embedding dimension 2)\n",
    "user_embedding = torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "item_embedding = torch.tensor([[0.7, 0.8], [0.9, 1.0], [1.1, 1.2]])\n",
    "\n",
    "# h_index and t_index based on the edges and negative samples\n",
    "# Each row represents a batch entry, and each column is a negative sample\n",
    "# Here, `0` and `1` are valid head indices (users), and we corrupt them by keeping valid and invalid tails\n",
    "h_index = torch.tensor([\n",
    "    [0, 0, 0],  # For first edge (0, 0, 3) with two negatives\n",
    "    [1, 2, 0]   # For second edge (1, 0, 4) with two negatives\n",
    "])\n",
    "t_index = torch.tensor([\n",
    "    [3, 4, 5],  # Original (0, 0, 3), and corrupted tails [4, 2]\n",
    "    [4, 4, 4]   # Original (1, 0, 4), and corrupted tails [5, 0]\n",
    "])\n",
    "\n",
    "# Gather head node embeddings\n",
    "# (num_nodes, dim)\n",
    "index_temp = h_index.unsqueeze(-1).expand(-1, -1, user_embedding.shape[-1])\n",
    "h_embeddings = user_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, h_index.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "# Adjust `t_index` to map to item IDs by subtracting `num_users`\n",
    "index_temp = (t_index - num_users).clamp(min=0)\n",
    "t_embeddings = item_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, index_temp.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "print(\"User Embedding Tensor:\\n\", user_embedding)\n",
    "print(\"Item Embedding Tensor:\\n\", item_embedding)\n",
    "print(\"Head Embeddings:\\n\", h_embeddings)\n",
    "print(\"Tail Embeddings:\\n\", t_embeddings)\n",
    "print(\"size head Embeddings:\\n\", h_embeddings.shape)\n",
    "print(\"size Tail Embeddings:\\n\", t_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bc3c5-a16b-4780-8342-c6f78b21f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "plot_ratings_vs_time(data)\n",
    "#print (data)\n",
    "#print (data['user', 'rates', 'movie'].rating[:20])\n",
    "#print (graph[\"movie\"].x[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9134d9-f7d4-4abd-82de-c51570b0aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0.])]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t_ranking = torch.zeros(5)\n",
    "h_ranking = torch.zeros(6)\n",
    "rankings1 = [t_ranking, h_ranking]\n",
    "print(rankings1)\n",
    "rankings2 = torch.cat([t_ranking, h_ranking], dim=0)\n",
    "print(rankings2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130c7989-98c0-4e7e-bbe7-04481f50f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_features = graph[\"user\"].x\n",
    "print (movies_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51b938-df62-4402-bbd5-f3832f447c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define your input and output directories.\n",
    "input_dir = \"/itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain_full_ckpt\"\n",
    "output_dir = \"/itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each checkpoint file in the input directory.\n",
    "for ckpt_file in os.listdir(input_dir):\n",
    "    # Only process files ending with .pth (or other extensions you expect)\n",
    "    if not ckpt_file.endswith(\".pth\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, ckpt_file)\n",
    "    print(f\"Processing {input_path} ...\")\n",
    "    \n",
    "    # Load the full checkpoint.\n",
    "    checkpoint = torch.load(input_path, map_location=\"cpu\")\n",
    "    full_state_dict = checkpoint[\"model\"]\n",
    "\n",
    "    # Extract the backbone (ultra) state_dict.\n",
    "    backbone_state_dict = {}\n",
    "    for key, value in full_state_dict.items():\n",
    "        if key.startswith(\"ultra.\"):\n",
    "            # Remove the \"ultra.\" prefix.\n",
    "            new_key = key[len(\"ultra.\"):]\n",
    "            backbone_state_dict[new_key] = value\n",
    "\n",
    "    # Construct the new checkpoint.\n",
    "    new_checkpoint = {\n",
    "        \"model\": backbone_state_dict,\n",
    "        \"optimizer\": checkpoint[\"optimizer\"]\n",
    "    }\n",
    "    \n",
    "    output_path = os.path.join(output_dir, ckpt_file)\n",
    "    torch.save(new_checkpoint, output_path)\n",
    "    print(f\"Saved backbone checkpoint to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07a6954-48cb-48a6-9b69-4eeaee492870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ckpt         dataset  epochs   bpe  FT   valid_mr  valid_mrr  valid_hits@1  \\\n",
      "0    -    Amazon_Games       8  3520   0  13.169436   0.493378      0.370810   \n",
      "1    -      Amazon_Men       8  2912   0  24.230614   0.247324      0.160186   \n",
      "2    -        Epinions       8  8337   0  27.958775   0.276970      0.162142   \n",
      "3    -  Amazon_Fashion       8  8363   0  23.999451   0.239994      0.158392   \n",
      "4    -   Amazon_Beauty       8  9184   0  22.984274   0.337647      0.238247   \n",
      "\n",
      "   valid_hits@3  valid_hits@10  valid_ndcg@10     test_mr  test_mrr  \\\n",
      "0      0.557613       0.728158       0.541948   16.391651  0.411673   \n",
      "1      0.274220       0.358971       0.285791   24.869064  0.230826   \n",
      "2      0.305725       0.515802       0.321015  268.101929  0.061357   \n",
      "3      0.259667       0.326501       0.279042   24.031866  0.231482   \n",
      "4      0.366086       0.531344       0.371713   26.416218  0.277981   \n",
      "\n",
      "   test_hits@1  test_hits@3  test_hits@10  test_ndcg@10  valid_ndcg@20  \\\n",
      "0     0.287000     0.466509      0.658937      0.461151            0.0   \n",
      "1     0.146525     0.252757      0.336725      0.268428            0.0   \n",
      "2     0.026436     0.056512      0.121754      0.229275            0.0   \n",
      "3     0.151115     0.249163      0.313106      0.271309            0.0   \n",
      "4     0.182146     0.299770      0.461290      0.308106            0.0   \n",
      "\n",
      "   test_ndcg@20  \n",
      "0           0.0  \n",
      "1           0.0  \n",
      "2           0.0  \n",
      "3           0.0  \n",
      "4           0.0  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\" \n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "\n",
    "# Read all entries\n",
    "df = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the results\n",
    "\n",
    "print(df.head())  # Use this if running in a terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2588a-3d3a-4878-8a13-a10a92d70c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/pretrain.py -c config/recommender/pretrain_all.yaml --gpus [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6aac0-77b8-4bbe-910c-f41567b4d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/trachsele/net_scratch/conda_envs/ba_bugfix/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "16:55:43   Random seed: 1024\n",
      "16:55:43   Config file: config/recommender/notebook_cfg.yaml\n",
      "16:55:43   {'checkpoint': '/itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain/inionsBeautyMl1m.pth',\n",
      " 'dataset': {'class': 'Gowalla',\n",
      "             'root': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data'},\n",
      " 'model': {'backbone_model': {'embedding_edge': {'dropout_rate': 0.03247182903513618,\n",
      "                                                 'hidden_dims': [16,\n",
      "                                                                 16,\n",
      "                                                                 16,\n",
      "                                                                 16,\n",
      "                                                                 16,\n",
      "                                                                 16],\n",
      "                                                 'use_dropout': True,\n",
      "                                                 'use_layer_norm': False},\n",
      "                              'simple_model': {'aggregate_func': 'sum',\n",
      "                                               'class': 'SimpleNBFNet',\n",
      "                                               'hidden_dims': [32,\n",
      "                                                               32,\n",
      "                                                               32,\n",
      "                                                               32,\n",
      "                                                               32,\n",
      "                                                               32,\n",
      "                                                               32],\n",
      "                                               'input_dim': 32,\n",
      "                                               'layer_norm': True,\n",
      "                                               'message_func': 'distmult',\n",
      "                                               'project_conv_emb': True,\n",
      "                                               'short_cut': True}},\n",
      "           'class': 'Gru-Ultra',\n",
      "           'edge_features': True,\n",
      "           'edge_projection': {'dropout_rate': 0.3743907806104132,\n",
      "                               'hidden_dims': [16, 16],\n",
      "                               'use_dropout': True,\n",
      "                               'use_layer_norm': False}},\n",
      " 'optimizer': {'backbone_conv_lr': 0.00017783663799881164,\n",
      "               'backbone_mlp_edge_lr': 0.0003360904636420548,\n",
      "               'class': 'AdamW',\n",
      "               'projection_edge_lr': 0.000248786603430893},\n",
      " 'output_dir': '/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/logs',\n",
      " 'task': {'adversarial_temperature': 1,\n",
      "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10', 'ndcg'],\n",
      "          'name': 'TransductiveInference',\n",
      "          'num_negative': 54,\n",
      "          'strict_negative': True},\n",
      " 'train': {'batch_per_epoch': 0,\n",
      "           'batch_size': 4,\n",
      "           'fine_tuning': {'num_epoch_proj': 0},\n",
      "           'gpus': [0],\n",
      "           'gradient_clip': False,\n",
      "           'init_linear_weights': True,\n",
      "           'log_interval': 100,\n",
      "           'loss': 'bce',\n",
      "           'num_epoch': 0,\n",
      "           'num_evals': 10,\n",
      "           'save_ckpt': False,\n",
      "           'save_results_db': False,\n",
      "           'target_metric': 'ndcg',\n",
      "           'test_batch_size': 4,\n",
      "           'wandb': False}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will evaluate vs all negatives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:55:56   Gowalla dataset\n",
      "16:55:56   #train: 712504, #valid: 97624, #test: 217242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discarded node_features\n",
      "bpe = 27404\n",
      "edge_attr.shape = torch.Size([1425008, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:55:56   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "16:55:56   Evaluate on valid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load rspmm extension. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Gowalla --epochs 0 --bpe 0 --gpus \"[0]\" --ckpt /itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain/inionsBeautyMl1m.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667960bc-c845-42a2-b821-68afbfd13555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Gowalla --epochs 0 --bpe 20000 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700fa38-a07d-4f5a-b665-c709694fb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Epinions --epochs 1 --bpe 10 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a51668e-e2a1-4613-be35-3305a3e138d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries for Yelp18 and Gowalla successfully added to the database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Manually insert Yelp18 data\n",
    "yelp18_data = (\n",
    "    \"-\", \"Yelp18\", 8, 17140, 0,  # ckpt, dataset, epochs, bpe, FT\n",
    "    1006.4, 0.0366413, 0.0136183, 0.0315789, 0.073482, 0.0,  # valid_mr, valid_mrr, valid_hits@1, valid_hits@3, valid_hits@10, valid_ndcg@10\n",
    "    1992.93, 0.017529, 0.00529698, 0.0132162, 0.034253,  # test_mr, test_mrr, test_hits@1, test_hits@3, test_hits@10\n",
    "    0.0900301, 0.0676829  # valid_ndcg@20, test_ndcg@20\n",
    ")\n",
    "\n",
    "# Manually insert Gowalla data\n",
    "gowalla_data = (\n",
    "    \"-\", \"Gowalla\", 8, 22265, 0,  # ckpt, dataset, epochs, bpe, FT\n",
    "    764.808, 0.080052, 0.0424691, 0.0786897, 0.149031, 0.0,  # valid_mr, valid_mrr, valid_hits@1, valid_hits@3, valid_hits@10, valid_ndcg@10\n",
    "    70747.3, 1.41349e-05, 0, 0, 0,  # test_mr, test_mrr, test_hits@1, test_hits@3, test_hits@10\n",
    "    0.1098, 0.0  # valid_ndcg@20, test_ndcg@20\n",
    ")\n",
    "\n",
    "# Corrected SQL query with double quotes around column names\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO experiments (\n",
    "    ckpt, dataset, epochs, bpe, FT,\n",
    "    valid_mr, valid_mrr, \"valid_hits@1\", \"valid_hits@3\", \"valid_hits@10\", \"valid_ndcg@10\",\n",
    "    test_mr, test_mrr, \"test_hits@1\", \"test_hits@3\", \"test_hits@10\",\n",
    "    \"valid_ndcg@20\", \"test_ndcg@20\"\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the inserts\n",
    "cursor.execute(insert_query, yelp18_data)\n",
    "cursor.execute(insert_query, gowalla_data)\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Entries for Yelp18 and Gowalla successfully added to the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77512c9d-00a8-40e8-8f75-ec3e7993b842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f89f1e-7b75-491c-9c8d-303b939e0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ckpt  dataset  epochs    bpe  FT  valid_mr  valid_mrr  valid_hits@1  \\\n",
      "0    -   Yelp18       8  17140   0  1006.400   0.036641      0.013618   \n",
      "1    -  Gowalla       8  22265   0   764.808   0.080052      0.042469   \n",
      "\n",
      "   valid_hits@3  valid_hits@10  valid_ndcg@10   test_mr  test_mrr  \\\n",
      "0      0.031579       0.073482            0.0   1992.93  0.017529   \n",
      "1      0.078690       0.149031            0.0  70747.30  0.000014   \n",
      "\n",
      "   test_hits@1  test_hits@3  test_hits@10 test_ndcg@10  valid_ndcg@20  \\\n",
      "0     0.005297     0.013216      0.034253         None        0.09003   \n",
      "1     0.000000     0.000000      0.000000         None        0.10980   \n",
      "\n",
      "   test_ndcg@20  \n",
      "0      0.067683  \n",
      "1      0.000000  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "\n",
    "# Read and filter only the newly inserted datasets\n",
    "query = 'SELECT * FROM experiments WHERE dataset IN (\"Yelp18\", \"Gowalla\")'\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "print(df.head())  # Use this if running in a terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c99d543-9391-44e0-90cc-917ca2c0ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed from the database.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import types\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Build a simple directed graph\n",
    "# ---------------------------\n",
    "# Let's assume 5 nodes (0,1,2,3,4).\n",
    "\n",
    "# Define forward edges: (0,1), (1,2), (2,3), (3,4)\n",
    "edge_index_forward = torch.tensor([[0, 1, 2, 3],\n",
    "                                   [1, 2, 3, 4]], dtype=torch.long)\n",
    "# Define reverse edges: (1,0), (2,1), (3,2), (4,3)\n",
    "edge_index_reverse = torch.tensor([[1, 2, 3, 4],\n",
    "                                   [0, 1, 2, 3]], dtype=torch.long)\n",
    "# Concatenate forward and reverse edges.\n",
    "edge_index = torch.cat([edge_index_forward, edge_index_reverse], dim=1)  # shape: [2, 8]\n",
    "\n",
    "# Set edge types: 0 for forward edges, 1 for reverse edges.\n",
    "edge_type_forward = torch.zeros(edge_index_forward.size(1), dtype=torch.long)\n",
    "edge_type_reverse = torch.ones(edge_index_reverse.size(1), dtype=torch.long)\n",
    "edge_type = torch.cat([edge_type_forward, edge_type_reverse], dim=0)  # shape: [8]\n",
    "\n",
    "# Edge attributes: for simplicity, each edge gets a feature vector of size 4.\n",
    "edge_attr = torch.ones((edge_index.size(1), 4), dtype=torch.float)\n",
    "\n",
    "# ---------------------------\n",
    "# Build target edges (new, undirected edges)\n",
    "# ---------------------------\n",
    "# These target edges should be different from those in edge_index.\n",
    "# In a recommendation setting the first row of target_edge_index gives the user IDs.\n",
    "# For example, let’s define three new edges: (0,2), (1,4), and (3,0)\n",
    "target_edge_index = torch.tensor([[0, 1, 3],\n",
    "                                  [2, 4, 0]], dtype=torch.long)\n",
    "# Create target edge attributes with the same feature dimension.\n",
    "target_edge_attr = torch.randn((target_edge_index.size(1), 4), dtype=torch.float)\n",
    "\n",
    "# ---------------------------\n",
    "# Set additional dataset attributes\n",
    "# ---------------------------\n",
    "num_nodes = 5           # Total number of nodes in the graph.\n",
    "# In this example, let’s assume that the test users are determined by the first row of target_edge_index.\n",
    "num_users = len(torch.unique(target_edge_index[0]))\n",
    "\n",
    "# Create the PyG Data object.\n",
    "test_data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    edge_attr=edge_attr,\n",
    "    target_edge_index=target_edge_index,\n",
    "    target_edge_attr=target_edge_attr,\n",
    "    num_nodes=num_nodes,\n",
    "    num_relations=2  # we have two relation types (0 and 1)\n",
    ")\n",
    "# Attach the number of test users.\n",
    "test_data.num_users = num_users\n",
    "\n",
    "# ---------------------------\n",
    "# Create a simple config and logger\n",
    "# ---------------------------\n",
    "cfg = types.SimpleNamespace()\n",
    "cfg.train = types.SimpleNamespace(test_batch_size=2)\n",
    "# We need the hidden_dims for the edge projection; here we use 4 (matching our edge feature dim).\n",
    "cfg.model = {\"edge_projection\": {\"hidden_dims\": [4]}}\n",
    "# Define the metrics you care about.\n",
    "cfg.task = types.SimpleNamespace(metric=[\"hits@1\", \"hits@3\", \"hits@10\"])\n",
    "cfg.k = 10\n",
    "\n",
    "class SimpleLogger:\n",
    "    def warning(self, msg):\n",
    "        print(msg)\n",
    "\n",
    "logger = SimpleLogger()\n",
    "\n",
    "# ---------------------------\n",
    "# Define a simple model\n",
    "# ---------------------------\n",
    "# (Replace this with your actual model if available.)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        # Your model would normally have parameters; here we return constant scores.\n",
    "    def forward(self, test_data, t_batch, generic_target):\n",
    "        # t_batch: shape (B, cand_size, 2)\n",
    "        B, cand_size, _ = t_batch.size()\n",
    "        # Return a constant score for each candidate.\n",
    "        return torch.full((B, cand_size), 0.5)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# ---------------------------\n",
    "# Prepare device and send data/model to it\n",
    "# ---------------------------\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# ---------------------------\n",
    "# Now call the test_per_user method.\n",
    "# ---------------------------\n",
    "# Note: This call uses your real tasks and model.\n",
    "result = test_per_user(cfg, model, test_data, device, logger,\n",
    "                        filtered_data=None, return_metrics=True)\n",
    "print(\"Test per user result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c8dba-5c11-46ab-872d-bf66245d1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_bugfix",
   "language": "python",
   "name": "ba_bugfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
