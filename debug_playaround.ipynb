{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e420fee2-0240-4834-a5d7-55c66184323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test interactions per user: 9.729940414428711\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultra import datasets\n",
    "from torch_geometric.datasets import MovieLens1M, MovieLens100K\n",
    "\n",
    "\n",
    "# Load MovieLens 1M dataset (adjust root if needed) push test\n",
    "#dataset = MovieLens1M(root='/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec/temp_pyg')\n",
    "dataset= datasets.Epinions(root= \"/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data\")\n",
    "test= dataset[2]\n",
    "\n",
    "# Assuming test.target_edge_index is defined and is a tensor of shape (2, num_edges)\n",
    "user_ids = test.target_edge_index[0]  # row 0 contains user indices\n",
    "unique_users, counts = torch.unique(user_ids, return_counts=True)\n",
    "avg_interactions = counts.float().mean().item()\n",
    "print(\"Average test interactions per user:\", avg_interactions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c8c673-780a-48bb-a83c-36e887e631dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0].edge_index.shapetorch.Size([2, 2194014])\n"
     ]
    }
   ],
   "source": [
    "from ultra import datasets\n",
    "\n",
    "dataset = datasets.Yelp18(root = \"/itet-stor/trachsele/net_scratch/tl4rec/model_outputs/data\")\n",
    "print (f\"dataset[0].edge_index.shape{: dataset[0].edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4db48-f865-42f6-abe7-7c5145a6198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "num_negatives = 2\n",
    "num_users = 3\n",
    "num_items = 3\n",
    "dim = 2\n",
    "\n",
    "# Embeddings for users and items (3 users, 3 items, embedding dimension 2)\n",
    "user_embedding = torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "item_embedding = torch.tensor([[0.7, 0.8], [0.9, 1.0], [1.1, 1.2]])\n",
    "\n",
    "# h_index and t_index based on the edges and negative samples\n",
    "# Each row represents a batch entry, and each column is a negative sample\n",
    "# Here, `0` and `1` are valid head indices (users), and we corrupt them by keeping valid and invalid tails\n",
    "h_index = torch.tensor([\n",
    "    [0, 0, 0],  # For first edge (0, 0, 3) with two negatives\n",
    "    [1, 2, 0]   # For second edge (1, 0, 4) with two negatives\n",
    "])\n",
    "t_index = torch.tensor([\n",
    "    [3, 4, 5],  # Original (0, 0, 3), and corrupted tails [4, 2]\n",
    "    [4, 4, 4]   # Original (1, 0, 4), and corrupted tails [5, 0]\n",
    "])\n",
    "\n",
    "# Gather head node embeddings\n",
    "# (num_nodes, dim)\n",
    "index_temp = h_index.unsqueeze(-1).expand(-1, -1, user_embedding.shape[-1])\n",
    "h_embeddings = user_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, h_index.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "# Adjust `t_index` to map to item IDs by subtracting `num_users`\n",
    "index_temp = (t_index - num_users).clamp(min=0)\n",
    "t_embeddings = item_embedding.unsqueeze(0).expand(batch_size,-1,-1).gather(1, index_temp.unsqueeze(-1).expand(-1, -1, dim))\n",
    "\n",
    "print(\"User Embedding Tensor:\\n\", user_embedding)\n",
    "print(\"Item Embedding Tensor:\\n\", item_embedding)\n",
    "print(\"Head Embeddings:\\n\", h_embeddings)\n",
    "print(\"Tail Embeddings:\\n\", t_embeddings)\n",
    "print(\"size head Embeddings:\\n\", h_embeddings.shape)\n",
    "print(\"size Tail Embeddings:\\n\", t_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bc3c5-a16b-4780-8342-c6f78b21f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "plot_ratings_vs_time(data)\n",
    "#print (data)\n",
    "#print (data['user', 'rates', 'movie'].rating[:20])\n",
    "#print (graph[\"movie\"].x[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9134d9-f7d4-4abd-82de-c51570b0aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0.])]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t_ranking = torch.zeros(5)\n",
    "h_ranking = torch.zeros(6)\n",
    "rankings1 = [t_ranking, h_ranking]\n",
    "print(rankings1)\n",
    "rankings2 = torch.cat([t_ranking, h_ranking], dim=0)\n",
    "print(rankings2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130c7989-98c0-4e7e-bbe7-04481f50f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_features = graph[\"user\"].x\n",
    "print (movies_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51b938-df62-4402-bbd5-f3832f447c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define your input and output directories.\n",
    "input_dir = \"/itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain_full_ckpt\"\n",
    "output_dir = \"/itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each checkpoint file in the input directory.\n",
    "for ckpt_file in os.listdir(input_dir):\n",
    "    # Only process files ending with .pth (or other extensions you expect)\n",
    "    if not ckpt_file.endswith(\".pth\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, ckpt_file)\n",
    "    print(f\"Processing {input_path} ...\")\n",
    "    \n",
    "    # Load the full checkpoint.\n",
    "    checkpoint = torch.load(input_path, map_location=\"cpu\")\n",
    "    full_state_dict = checkpoint[\"model\"]\n",
    "\n",
    "    # Extract the backbone (ultra) state_dict.\n",
    "    backbone_state_dict = {}\n",
    "    for key, value in full_state_dict.items():\n",
    "        if key.startswith(\"ultra.\"):\n",
    "            # Remove the \"ultra.\" prefix.\n",
    "            new_key = key[len(\"ultra.\"):]\n",
    "            backbone_state_dict[new_key] = value\n",
    "\n",
    "    # Construct the new checkpoint.\n",
    "    new_checkpoint = {\n",
    "        \"model\": backbone_state_dict,\n",
    "        \"optimizer\": checkpoint[\"optimizer\"]\n",
    "    }\n",
    "    \n",
    "    output_path = os.path.join(output_dir, ckpt_file)\n",
    "    torch.save(new_checkpoint, output_path)\n",
    "    print(f\"Saved backbone checkpoint to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07a6954-48cb-48a6-9b69-4eeaee492870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ckpt         dataset  epochs   bpe  FT   valid_mr  valid_mrr  valid_hits@1  \\\n",
      "0    -    Amazon_Games       8  3520   0  13.169436   0.493378      0.370810   \n",
      "1    -      Amazon_Men       8  2912   0  24.230614   0.247324      0.160186   \n",
      "2    -        Epinions       8  8337   0  27.958775   0.276970      0.162142   \n",
      "3    -  Amazon_Fashion       8  8363   0  23.999451   0.239994      0.158392   \n",
      "4    -   Amazon_Beauty       8  9184   0  22.984274   0.337647      0.238247   \n",
      "\n",
      "   valid_hits@3  valid_hits@10  valid_ndcg@10     test_mr  test_mrr  \\\n",
      "0      0.557613       0.728158       0.541948   16.391651  0.411673   \n",
      "1      0.274220       0.358971       0.285791   24.869064  0.230826   \n",
      "2      0.305725       0.515802       0.321015  268.101929  0.061357   \n",
      "3      0.259667       0.326501       0.279042   24.031866  0.231482   \n",
      "4      0.366086       0.531344       0.371713   26.416218  0.277981   \n",
      "\n",
      "   test_hits@1  test_hits@3  test_hits@10  test_ndcg@10  valid_ndcg@20  \\\n",
      "0     0.287000     0.466509      0.658937      0.461151            0.0   \n",
      "1     0.146525     0.252757      0.336725      0.268428            0.0   \n",
      "2     0.026436     0.056512      0.121754      0.229275            0.0   \n",
      "3     0.151115     0.249163      0.313106      0.271309            0.0   \n",
      "4     0.182146     0.299770      0.461290      0.308106            0.0   \n",
      "\n",
      "   test_ndcg@20  \n",
      "0           0.0  \n",
      "1           0.0  \n",
      "2           0.0  \n",
      "3           0.0  \n",
      "4           0.0  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\" \n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "\n",
    "# Read all entries\n",
    "df = pd.read_sql(\"SELECT * FROM experiments\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the results\n",
    "\n",
    "print(df.head())  # Use this if running in a terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2588a-3d3a-4878-8a13-a10a92d70c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/pretrain.py -c config/recommender/pretrain_all.yaml --gpus [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6aac0-77b8-4bbe-910c-f41567b4d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset BookX --epochs 1 --bpe 0 --gpus \"[0]\" --ckpt /itet-stor/trachsele/net_scratch/tl4rec/ckpts/pretrain/Epinions.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667960bc-c845-42a2-b821-68afbfd13555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Gowalla --epochs 0 --bpe 20000 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700fa38-a07d-4f5a-b665-c709694fb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run script/run.py -c config/recommender/notebook_cfg.yaml --dataset Epinions --epochs 1 --bpe 10 --gpus \"[0]\" --ckpt null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a51668e-e2a1-4613-be35-3305a3e138d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries for Yelp18 and Gowalla successfully added to the database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Manually insert Yelp18 data\n",
    "yelp18_data = (\n",
    "    \"-\", \"Yelp18\", 8, 17140, 0,  # ckpt, dataset, epochs, bpe, FT\n",
    "    1006.4, 0.0366413, 0.0136183, 0.0315789, 0.073482, 0.0,  # valid_mr, valid_mrr, valid_hits@1, valid_hits@3, valid_hits@10, valid_ndcg@10\n",
    "    1992.93, 0.017529, 0.00529698, 0.0132162, 0.034253,  # test_mr, test_mrr, test_hits@1, test_hits@3, test_hits@10\n",
    "    0.0900301, 0.0676829  # valid_ndcg@20, test_ndcg@20\n",
    ")\n",
    "\n",
    "# Manually insert Gowalla data\n",
    "gowalla_data = (\n",
    "    \"-\", \"Gowalla\", 8, 22265, 0,  # ckpt, dataset, epochs, bpe, FT\n",
    "    764.808, 0.080052, 0.0424691, 0.0786897, 0.149031, 0.0,  # valid_mr, valid_mrr, valid_hits@1, valid_hits@3, valid_hits@10, valid_ndcg@10\n",
    "    70747.3, 1.41349e-05, 0, 0, 0,  # test_mr, test_mrr, test_hits@1, test_hits@3, test_hits@10\n",
    "    0.1098, 0.0  # valid_ndcg@20, test_ndcg@20\n",
    ")\n",
    "\n",
    "# Corrected SQL query with double quotes around column names\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO experiments (\n",
    "    ckpt, dataset, epochs, bpe, FT,\n",
    "    valid_mr, valid_mrr, \"valid_hits@1\", \"valid_hits@3\", \"valid_hits@10\", \"valid_ndcg@10\",\n",
    "    test_mr, test_mrr, \"test_hits@1\", \"test_hits@3\", \"test_hits@10\",\n",
    "    \"valid_ndcg@20\", \"test_ndcg@20\"\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the inserts\n",
    "cursor.execute(insert_query, yelp18_data)\n",
    "cursor.execute(insert_query, gowalla_data)\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Entries for Yelp18 and Gowalla successfully added to the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77512c9d-00a8-40e8-8f75-ec3e7993b842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/usr/itetnas04/data-scratch-01/trachsele/data/tl4rec\") \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f89f1e-7b75-491c-9c8d-303b939e0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ckpt  dataset  epochs    bpe  FT  valid_mr  valid_mrr  valid_hits@1  \\\n",
      "0    -   Yelp18       8  17140   0  1006.400   0.036641      0.013618   \n",
      "1    -  Gowalla       8  22265   0   764.808   0.080052      0.042469   \n",
      "\n",
      "   valid_hits@3  valid_hits@10  valid_ndcg@10   test_mr  test_mrr  \\\n",
      "0      0.031579       0.073482            0.0   1992.93  0.017529   \n",
      "1      0.078690       0.149031            0.0  70747.30  0.000014   \n",
      "\n",
      "   test_hits@1  test_hits@3  test_hits@10 test_ndcg@10  valid_ndcg@20  \\\n",
      "0     0.005297     0.013216      0.034253         None        0.09003   \n",
      "1     0.000000     0.000000      0.000000         None        0.10980   \n",
      "\n",
      "   test_ndcg@20  \n",
      "0      0.067683  \n",
      "1      0.000000  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "\n",
    "# Read and filter only the newly inserted datasets\n",
    "query = 'SELECT * FROM experiments WHERE dataset IN (\"Yelp18\", \"Gowalla\")'\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "print(df.head())  # Use this if running in a terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c99d543-9391-44e0-90cc-917ca2c0ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed from the database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_FILE = \"//itet-stor/trachsele/net_scratch/tl4rec/model_outputs/results.db\" \n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Delete rows where dataset is 'LastFM' or 'BookX'\n",
    "cursor.execute(\"DELETE FROM experiments WHERE dataset IN ('LastFM', 'BookX')\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Rows removed from the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c8dba-5c11-46ab-872d-bf66245d1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_bugfix",
   "language": "python",
   "name": "ba_bugfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
